{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6336605d-a676-43c1-9eb5-9e1c224c1ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.models import resnet50, ResNet50_Weights\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "64bce1df-22c7-4a4f-998b-eb59c623ef16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set device\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b11ded7-ecf6-4397-a203-170c5943b5af",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = '..\\data\\ImageNet_2012'\n",
    "split = 'train'\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(256), # Met la taille du plus petit côté de l'image à 256 (l'autre reste proportionnel par rapport au rapport initial).\n",
    "    transforms.CenterCrop(224), # Sélectionne le carré de côté 224 à partir du centre de l'image\n",
    "    transforms.ToTensor(), # Convertir image PIL en tenseur avec des valeurs comprises dans [0,1]\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]), # normalise les valeurs du tenseur\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b36f7f53-80c6-4510-a6cf-9ad7e79c670b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instanciation de la classe imagenet avec une transformation spécifique\n",
    "dataset = datasets.ImageNet(root, split=split, transform=transform)\n",
    "avgpool_list = torch.tensor([]).to(DEVICE)\n",
    "# on enregistre les labels \n",
    "labels_list = torch.tensor(dataset.targets)\n",
    "torch.save(labels_list, '../data/saved_outputs/penultimate_layer_labels.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6d9c4c4a-b478-4fbb-bdd4-163c7d3f49b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = resnet50(weights=ResNet50_Weights.DEFAULT)\n",
    "model = model.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fa52148e-88d6-415d-8e70-485f8dbde37c",
   "metadata": {},
   "outputs": [],
   "source": [
    "activation = {}\n",
    "# Fonction pour obtenir les sorties d'une couche spécifique\n",
    "def getActivation(name):\n",
    "  # the hook signature\n",
    "  def hook(model, input, output):\n",
    "    activation[name] = output.detach()\n",
    "  return hook\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "95a8472d-422c-45da-beaf-a4144949d759",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "num_workers = 4\n",
    "pin_memory = True\n",
    "number_batch_size_segmentation = 200\n",
    "segmentation_index = 0\n",
    "min_size_segmentation = number_batch_size_segmentation*batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6e8397a4-972c-4552-9a31-dd006817f9fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "h = model.avgpool.register_forward_hook(getActivation('avgpool'))\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, num_workers=num_workers, pin_memory=pin_memory) # dépend des specs de la machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e568aecb-e058-45e5-8e90-e8e820bb78ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation: 100%|████████████████████████████████████████████████████████████████| 5005/5005 [1:04:29<00:00,  1.29it/s]\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for images, labels in tqdm(dataloader, desc=\"Evaluation\"):\n",
    "\n",
    "        if avgpool_list.shape[0] >= min_size_segmentation:\n",
    "            # on sauvegarde le tenseur dans un format optimisé pytorch\n",
    "            torch.save(avgpool_list, f'../data/saved_outputs/penultimate_layer_outputs/penultimate_layer_outputs_{segmentation_index}.pt')\n",
    "            avgpool_list = torch.tensor([]).to(DEVICE)\n",
    "            segmentation_index+=1\n",
    "            \n",
    "        # Copie des images/labels sur le GPU\n",
    "        images = images.to(DEVICE)\n",
    "\n",
    "        # On récupère les prédictions du programme et on diminue la précision\n",
    "        outputs = model(images)\n",
    "\n",
    "        # on enlève les dimensions de taille 1, on concatène le résultat dans avgpool_list \n",
    "        avgpool_list = torch.cat([avgpool_list, activation['avgpool'].squeeze()],dim=0)     \n",
    "         \n",
    "torch.save(avgpool_list, f'../data/saved_outputs/penultimate_layer_outputs/penultimate_layer_outputs_{segmentation_index}.pt')\n",
    "del avgpool_list, outputs, images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9d247c50-71e2-4c89-a790-db05de229944",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chargement: 100%|██████████████████████████████████████████████████████████████████████| 25/25 [15:23<00:00, 36.94s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1280000, 2048])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ces lignes ne sont pas nécessaires, on peut s'en sortir avec les tenseurs segmentés, pour les exécuter 32GO de Ram minimum sont recommandés.\n",
    "penultimate_layer_outputs = torch.tensor([])\n",
    "for i in tqdm(range(segmentation_index+1), desc=\"Chargement\"):\n",
    "    penultimate_layer_outputs = torch.cat([penultimate_layer_outputs, torch.load(f'../data/saved_outputs/penultimate_layer_outputs/penultimate_layer_outputs_{i}.pt', map_location='cpu')], dim=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "31375760-c198-40e3-bc77-e6e80aaca40b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sauvegarde du tenseur\n",
    "torch.save(penultimate_layer_outputs, f'../data/saved_outputs/penultimate_layer_outputs_all.pt')\n",
    "del penultimate_layer_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "90b33065-9c64-4f6a-8dd7-8f64fce502a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pour la récupération :\n",
    "penultimate_layer_outputs = torch.load('../data/saved_outputs/penultimate_layer_outputs_all.pt', map_location='cpu')\n",
    "labels_list = torch.load('../data/saved_outputs/penultimate_layer_labels.pt', map_location=DEVICE)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
