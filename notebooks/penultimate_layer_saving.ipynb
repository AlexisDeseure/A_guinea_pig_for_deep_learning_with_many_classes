{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "91012d7f-b00f-45b6-bfe5-893e72b6a897",
   "metadata": {},
   "source": [
    "# Penultimate layer saving\n",
    "This notebook aims to save the penultimate outputs in different files to create a new dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b0975be-b83a-4b2c-86d1-79fb7085f93a",
   "metadata": {},
   "source": [
    "## Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6336605d-a676-43c1-9eb5-9e1c224c1ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.models import resnet50, ResNet50_Weights\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7732f6f7-ab2c-44c7-a57d-7942a217e969",
   "metadata": {},
   "source": [
    "## Set up hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03249e91-976f-4ad1-a4fd-5ed45ff90c49",
   "metadata": {},
   "source": [
    "#### For ImageNet dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b11ded7-ecf6-4397-a203-170c5943b5af",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = '..\\data\\ImageNet_2012'# root address for ImageNet dataset\n",
    "split = 'val' # train or val for ImageNet\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(256), # Sets the size of the smallest side of the image to 256 \n",
    "    transforms.CenterCrop(224), # Selects the square with side 224 from the center of the image\n",
    "    transforms.ToTensor(), # Convert PIL image into tensor with values within [0, 1]\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]), # normalizes tensor values \n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1026c64e-2fd3-45f7-b6d5-94730d0f9fae",
   "metadata": {},
   "source": [
    "#### For model inference and save outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "95a8472d-422c-45da-beaf-a4144949d759",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256 # batch length to accelerate inference\n",
    "num_workers = 4 # number of subprocesses \n",
    "pin_memory = True \n",
    "number_batch_size_segmentation = 200 # number of batch per files saved\n",
    "segmentation_index = 0 # initiate counter for files\n",
    "min_size_segmentation = number_batch_size_segmentation*batch_size # number of output tensors for each complete file\n",
    "\n",
    "# address for outputs\n",
    "saving_folder = f'../data/saved_outputs/{split}' \n",
    "if not os.path.exists(f\"{saving_folder}/penultimate_layer_outputs\"):\n",
    "    os.makedirs(f\"{saving_folder}/penultimate_layer_outputs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef25b285-94a7-493a-899f-156c6ca7f931",
   "metadata": {},
   "source": [
    "## Initialization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "64bce1df-22c7-4a4f-998b-eb59c623ef16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set device\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa52148e-88d6-415d-8e70-485f8dbde37c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define elements to get penultimate layer outputs\n",
    "avgpool_list = torch.tensor([]).to(DEVICE) \n",
    "activation = {}\n",
    "def getActivation(name):\n",
    "  # get the penultimate layer activation\n",
    "  def hook(model, input, output):\n",
    "    activation[name] = output.detach()\n",
    "  return hook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e2fab49d-94c1-474e-91b6-68ca6331253c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset initialization\n",
    "dataset = datasets.ImageNet(root, split=split, transform=transform)\n",
    "\n",
    "# model initialization\n",
    "model = resnet50(weights=ResNet50_Weights.DEFAULT)\n",
    "model = model.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6e8397a4-972c-4552-9a31-dd006817f9fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize getActivation\n",
    "h = model.avgpool.register_forward_hook(getActivation('avgpool'))\n",
    "\n",
    "# Initialize data loader for batch subdivision\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, num_workers=num_workers, pin_memory=pin_memory) # modify parameters according to device specifications"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d137db88-6953-4f68-83a3-0f65fd34edeb",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e568aecb-e058-45e5-8e90-e8e820bb78ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation: 100%|█████████████████████████████████████████████████████████████████████████████████████████████| 196/196 [03:05<00:00,  1.05it/s]\n"
     ]
    }
   ],
   "source": [
    "model.eval() # desactivate specific layers/parts of the model for evaluation\n",
    "correct_predictions=0\n",
    "with torch.no_grad(): # turning off gradients computation\n",
    "    for images, labels in tqdm(dataloader, desc=\"Evaluation\"):\n",
    "\n",
    "        if avgpool_list.shape[0] >= min_size_segmentation:\n",
    "            # Save tensor in optimized PyTorch format\n",
    "            torch.save(avgpool_list, f'{saving_folder}/penultimate_layer_outputs/penultimate_layer_outputs_{segmentation_index}.pt')\n",
    "            avgpool_list = torch.tensor([]).to(DEVICE)\n",
    "            segmentation_index+=1\n",
    "            \n",
    "        # Copy images/labels tensors to GPU\n",
    "        images = images.to(DEVICE)\n",
    "        labels = labels.to(DEVICE)\n",
    "        \n",
    "        # Recover program predictions and reduce accuracy\n",
    "        outputs = model(images)\n",
    "        \n",
    "        # Concatenation in avgpool_list of penultimate outputs for the current batch\n",
    "        avgpool_list = torch.cat([avgpool_list, activation['avgpool'].squeeze()],dim=0) \n",
    "\n",
    "        # Compute correct predictions for the batch and increment correct_predictions\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct_predictions += (predicted == labels).sum().item()\n",
    "\n",
    "# Save the last file\n",
    "torch.save(avgpool_list, f'{saving_folder}/penultimate_layer_outputs/penultimate_layer_outputs_{segmentation_index}.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5a7893a1-2b0a-4506-ad94-87c4920c945e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 80.342%\n"
     ]
    }
   ],
   "source": [
    "# Print accuracy\n",
    "accuracy = 100 * correct_predictions / len(dataset)\n",
    "print(f'Accuracy: {accuracy}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18e9e96b-5c64-4027-88db-0e20a2c2c240",
   "metadata": {},
   "source": [
    "## Save results\n",
    "Outputs are already saved during evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "466d8184-1ec3-4301-99b9-f727a69d4add",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save labels in a single file\n",
    "labels_list = torch.tensor(dataset.targets)\n",
    "torch.save(labels_list, f'{saving_folder}/penultimate_layer_labels.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9b06cd78-a4ad-4995-8d3d-ec8f7473fbf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save data as JSON to easily construct a dataset\n",
    "data = {\n",
    "    \"last_file_indice\" : segmentation_index,\n",
    "    \"min_size_segmentation\" : min_size_segmentation\n",
    "}\n",
    "with open(f'{saving_folder}/penultimate_layer_outputs/data.json', 'w') as js:\n",
    "    json.dump(data, js)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f0a041",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
