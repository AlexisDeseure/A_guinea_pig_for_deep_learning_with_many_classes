{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a06f1a0e-6d4d-42e1-a8f3-56899e86dda3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.models import resnet50, ResNet50_Weights\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3536cd33-e099-4572-9e50-5bf72c65989e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set device\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1ca84311-c062-439c-b673-a0761fb7b28f",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = '..\\data\\ImageNet_2012'\n",
    "split = 'train'\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(256), # met la taille du plus petit côté de l'image à 256 (l'autre reste proportionnel par rapport au rapport initial)\n",
    "    transforms.CenterCrop(224), # sélectionne le carré de côté 224 à partir du centre de l'image\n",
    "    transforms.ToTensor(), # convertir image PIL en tenseur avec des valeurs comprises dans [0,1]\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]), # normalise les valeurs du tenseur\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4308f589-ee0e-479f-9cd9-d727efbe2342",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instanciation de la classe imagenet avec une transformation spécifique\n",
    "dataset = datasets.ImageNet(root, split=split, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1a942d60-bea5-42da-a773-51d512de71ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instanciation du modèle\n",
    "model = resnet50(weights=ResNet50_Weights.DEFAULT)\n",
    "model = model.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f0865e03-f214-47a5-9528-0ff8e5e08509",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m----> 2\u001b[0m dataloader \u001b[38;5;241m=\u001b[39m DataLoader(\u001b[43mdataset\u001b[49m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m256\u001b[39m, num_workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m, pin_memory\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;66;03m# dépend des specs de la machine\u001b[39;00m\n\u001b[0;32m      3\u001b[0m correct_predictions \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n",
      "\u001b[1;31mNameError\u001b[0m: name 'dataset' is not defined"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "dataloader = DataLoader(dataset, batch_size=256, num_workers=4, pin_memory=True) # dépend des specs de la machine\n",
    "correct_predictions = 0\n",
    "with torch.no_grad():\n",
    "    for images, labels in tqdm(dataloader, desc=\"Evaluation\"):\n",
    "        # Copie des images/labels sur le GPU\n",
    "        images = images.to(DEVICE)\n",
    "        labels = labels.to(DEVICE)\n",
    "\n",
    "        # On récupère les préictions du programme\n",
    "        outputs = model(images)\n",
    "\n",
    "        # Obtention des classes prédites (pour chaque prédiction)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "        # Ajout des prédictions correctes au total\n",
    "        correct_predictions += (predicted == labels).sum().item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daaba77d-95f2-4a2d-a695-0df01a3b2e80",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Calcul du pourcentage de bonnes classifications\n",
    "accuracy = 100 * correct_predictions / len(dataset)\n",
    "\n",
    "print(f'Accuracy: {accuracy}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8a1aa780-a8ef-4912-aa66-28b48ecd8e16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 1., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 1.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = 10  # Nombre de vecteurs\n",
    "size = 1000  # Taille de chaque vecteur\n",
    "indices = torch.tensor([i for i in range(n)])  # Indices où placer le 1\n",
    "\n",
    "# Créer une matrice de n vecteurs de taille 'size' remplis de zéros\n",
    "matrice = torch.zeros(n, size)\n",
    "\n",
    "# Placer un 1 à l'indice spécifié dans chaque vecteur\n",
    "matrice.scatter_(1, indices.unsqueeze(1), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd4b6e6e-feeb-4b1f-a939-1b107012418b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
