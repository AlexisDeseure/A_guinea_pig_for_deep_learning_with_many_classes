{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6336605d-a676-43c1-9eb5-9e1c224c1ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.models import resnet50, ResNet50_Weights\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "64bce1df-22c7-4a4f-998b-eb59c623ef16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set device\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9b11ded7-ecf6-4397-a203-170c5943b5af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# root = '..\\data\\ImageNet_2012'\n",
    "root = \"../../../../../../Documents/ImageNet_2012\"\n",
    "\n",
    "split = 'train'\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(256), # Met la taille du plus petit côté de l'image à 256 (l'autre reste proportionnel par rapport au rapport initial).\n",
    "    transforms.CenterCrop(224), # Sélectionne le carré de côté 224 à partir du centre de l'image\n",
    "    transforms.ToTensor(), # Convertir image PIL en tenseur avec des valeurs comprises dans [0,1]\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]), # normalise les valeurs du tenseur\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b36f7f53-80c6-4510-a6cf-9ad7e79c670b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instanciation de la classe imagenet avec une transformation spécifique\n",
    "dataset = datasets.ImageNet(root, split=split, transform=transform)\n",
    "avgpool_list = torch.tensor([]).to(DEVICE)\n",
    "# on enregistre les labels \n",
    "labels_list = torch.tensor(dataset.targets)\n",
    "torch.save(labels_list, '../data/saved_outputs/penultimate_layer_labels.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6d9c4c4a-b478-4fbb-bdd4-163c7d3f49b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = resnet50(weights=ResNet50_Weights.DEFAULT)\n",
    "model = model.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fa52148e-88d6-415d-8e70-485f8dbde37c",
   "metadata": {},
   "outputs": [],
   "source": [
    "activation = {}\n",
    "# Fonction pour obtenir les sorties d'une couche spécifique\n",
    "def getActivation(name):\n",
    "  # the hook signature\n",
    "  def hook(model, input, output):\n",
    "    activation[name] = output.detach()\n",
    "  return hook\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "95a8472d-422c-45da-beaf-a4144949d759",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "num_workers = 4\n",
    "pin_memory = True\n",
    "number_batch_size_segmentation = 200\n",
    "segmentation_index = 0\n",
    "min_size_segmentation = number_batch_size_segmentation*batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6e8397a4-972c-4552-9a31-dd006817f9fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "h = model.avgpool.register_forward_hook(getActivation('avgpool'))\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, num_workers=num_workers, pin_memory=pin_memory) # dépend des specs de la machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e568aecb-e058-45e5-8e90-e8e820bb78ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation:   0%|                                                                             | 0/5005 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "correct_predictions=0\n",
    "with torch.no_grad():\n",
    "    for images, labels in tqdm(dataloader, desc=\"Evaluation\"):\n",
    "\n",
    "        if avgpool_list.shape[0] >= min_size_segmentation:\n",
    "            # on sauvegarde le tenseur dans un format optimisé pytorch\n",
    "            torch.save(avgpool_list, f'../data/saved_outputs/penultimate_layer_outputs/penultimate_layer_outputs_{segmentation_index}.pt')\n",
    "            avgpool_list = torch.tensor([]).to(DEVICE)\n",
    "            segmentation_index+=1\n",
    "            \n",
    "        # Copie des images/labels sur le GPU\n",
    "        images = images.to(DEVICE)\n",
    "        labels = labels.to(DEVICE)\n",
    "        \n",
    "        # On récupère les prédictions du programme et on diminue la précision\n",
    "        outputs = model(images)\n",
    "        \n",
    "        # on enlève les dimensions de taille 1, on concatène le résultat dans avgpool_list \n",
    "        avgpool_list = torch.cat([avgpool_list, activation['avgpool'].squeeze()],dim=0) \n",
    "\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "        # Ajout des prédictions correctes au total\n",
    "        correct_predictions += (predicted == labels).sum().item()\n",
    "         \n",
    "torch.save(avgpool_list, f'../data/saved_outputs/penultimate_layer_outputs/penultimate_layer_outputs_{segmentation_index}.pt')\n",
    "del avgpool_list, outputs, images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5a7893a1-2b0a-4506-ad94-87c4920c945e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 91.30519284371202%\n"
     ]
    }
   ],
   "source": [
    "accuracy = 100 * correct_predictions / len(dataset)\n",
    "print(f'Accuracy: {accuracy}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9b06cd78-a4ad-4995-8d3d-ec8f7473fbf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enregistrer les données sous forme de JSON pour mieux traiter les fichiers quels que soient les paramètres donnés.\n",
    "# Création du dictionnaire\n",
    "data = {\n",
    "    \"last_file_indice\" : segmentation_index,\n",
    "    \"min_size_segmentation\" : min_size_segmentation\n",
    "}\n",
    "# Écriture dans un fichier JSON\n",
    "with open('../data/saved_outputs/penultimate_layer_outputs/data.json', 'w') as js:\n",
    "    json.dump(data, js)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "281fd3a1-9a29-4569-ad5e-c813cd24174d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
