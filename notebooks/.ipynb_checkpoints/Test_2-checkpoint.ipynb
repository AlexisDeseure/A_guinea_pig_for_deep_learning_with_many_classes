{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3dcf9a12-76d1-45e5-b873-db209670cd22",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrateur\\AppData\\Local\\Temp\\ipykernel_4272\\1469002280.py:7: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.models import resnet50, ResNet50_Weights\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3bef7c83-b657-4119-a24e-a0fef4a8ec37",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = './data'\n",
    "split = 'val'\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(256), # met la taille du plus petit côté de l'image à 256 (l'autre reste proportionnel par rapport au rapport initial)\n",
    "    transforms.CenterCrop(224), # sélectionne le carré de côté 224 à partir du centre de l'image\n",
    "    transforms.ToTensor(), # convertir image PIL en tenseur avec des valeurs comprises dans [0,1]\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]), # normalise les valeurs du tenseur\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e8b558c8-e34a-440b-b1c9-fba47fc5ecb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "avgpool_list = []\n",
    "fc_list = []\n",
    "dataset = datasets.ImageNet(root, split=split, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad81922e-1c29-4b4b-8fe3-8b1ca39dd10e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataloader = DataLoader(dataset, batch_size=256, num_workers=4, pin_memory=True) # dépend des specs de la machine\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4a46ee5b-c98a-4255-9078-12ef45607c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c0951099-2978-43a0-a014-3e0ebaacb202",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = resnet50(weights=ResNet50_Weights.DEFAULT)\n",
    "model = model.to(DEVICE)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9e0b577a-87e9-4fb7-aed6-cb60f501c8bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "activation = {}\n",
    "def getActivation(name):\n",
    "  # the hook signature\n",
    "  def hook(model, input, output):\n",
    "    activation[name] = output.detach()\n",
    "  return hook\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8741c5dc-0bde-4556-95b0-23e1b84d10ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "h1 = model.avgpool.register_forward_hook(getActivation('avgpool'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "29d58a2d-b918-4d81-b011-509926beb2f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation: 100%|████████████████████████████████████████████████████████████████████| 196/196 [01:27<00:00,  2.25it/s]\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    for images, labels in tqdm(dataloader, desc=\"Evaluation\"):\n",
    "        images = images.to(DEVICE)\n",
    "        labels = labels.to(DEVICE)\n",
    "        # forward pass -- getting the outputs\n",
    "        out = model(images)\n",
    "        # collect the activations in the correct list\n",
    "        avgpool_list.append(activation['avgpool'])\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "61af3332-6a67-4f26-91c3-5e9a8183b19e",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_fc = torch.cat(avgpool_list,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f28c0091-1000-4e05-9fca-58d5e10cca38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50000, 2048, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "print(input_fc.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ab7ef5c7-427b-4dd3-a74e-aef23b84c049",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m t_np \u001b[38;5;241m=\u001b[39m \u001b[43minput_fc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m#convert to Numpy array\u001b[39;00m\n\u001b[0;32m      2\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(t_np) \u001b[38;5;66;03m#convert to a dataframe\u001b[39;00m\n\u001b[0;32m      3\u001b[0m df\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtestfile\u001b[39m\u001b[38;5;124m\"\u001b[39m,index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;66;03m#save to file\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first."
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6d693ff-07dd-4fe3-9164-27fd365e5daf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
